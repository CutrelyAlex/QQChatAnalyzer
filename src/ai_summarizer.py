"""
AIæ€»ç»“æ¨¡å— - ä½¿ç”¨OpenAIç”Ÿæˆåˆ›æ„é£æ ¼çš„èŠå¤©æ€»ç»“
"""

import os
import json
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime

logger = logging.getLogger(__name__)

# OpenAI å®¢æˆ·ç«¯
_openai_client = None


def get_openai_client():
    """è·å–æˆ–åˆ›å»ºOpenAIå®¢æˆ·ç«¯"""
    global _openai_client
    
    if _openai_client is None:
        try:
            from openai import OpenAI
            
            api_key = os.environ.get('OPENAI_API_KEY', '')
            base_url = os.environ.get('OPENAI_API_BASE', '')
            
            if not api_key:
                return None
            
            kwargs = {'api_key': api_key}
            if base_url:
                kwargs['base_url'] = base_url
            
            _openai_client = OpenAI(**kwargs)
        except ImportError:
            logger.warning("OpenAI library not installed. Run: pip install openai")
            return None
        except Exception as e:
            logger.error(f"Failed to create OpenAI client: {e}")
            return None
    
    return _openai_client


class AISummarizer:
    """
    AIæ€»ç»“å™¨ - ä½¿ç”¨OpenAIç”Ÿæˆåˆ›æ„é£æ ¼çš„èŠå¤©æ€»ç»“
    """
    
    def __init__(self, model: str = None, max_tokens: int = 2000, 
                 api_key: str = None, base_url: str = None):
        """
        åˆå§‹åŒ–AIæ€»ç»“å™¨
        
        Args:
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
            max_tokens: ç”Ÿæˆçš„æœ€å¤§tokenæ•°
            api_key: OpenAI APIå¯†é’¥ï¼ˆå¯é€‰ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡å¦‚æœªæä¾›ï¼‰
            base_url: OpenAI APIåŸºç¡€URLï¼ˆå¯é€‰ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡å¦‚æœªæä¾›ï¼‰
        """
        self.model = model or os.environ.get('OPENAI_MODEL', 'gpt-4o-mini')
        self.max_tokens = max_tokens
        
        # å¦‚æœæä¾›äº†è‡ªå®šä¹‰é…ç½®ï¼Œåˆ›å»ºæ–°å®¢æˆ·ç«¯ï¼›å¦åˆ™ä½¿ç”¨å…¨å±€å®¢æˆ·ç«¯
        if api_key or base_url:
            self.client = self._create_custom_client(api_key, base_url)
        else:
            self.client = get_openai_client()
    
    def _create_custom_client(self, api_key: str = None, base_url: str = None):
        """åˆ›å»ºè‡ªå®šä¹‰OpenAIå®¢æˆ·ç«¯"""
        try:
            from openai import OpenAI
            
            # ä½¿ç”¨æä¾›çš„æˆ–ç¯å¢ƒå˜é‡ä¸­çš„å€¼
            final_api_key = api_key or os.environ.get('OPENAI_API_KEY', '')
            final_base_url = base_url or os.environ.get('OPENAI_API_BASE', '')
            
            if not final_api_key:
                return None
            
            kwargs = {'api_key': final_api_key}
            if final_base_url:
                kwargs['base_url'] = final_base_url
            
            return OpenAI(**kwargs)
        except ImportError:
            logger.warning("OpenAI library not installed. Run: pip install openai")
            return None
        except Exception as e:
            logger.error(f"Failed to create OpenAI client: {e}")
            return None
    
    def is_available(self) -> bool:
        """æ£€æŸ¥AIæœåŠ¡æ˜¯å¦å¯ç”¨"""
        return self.client is not None
    
    def generate_personal_summary(self, stats: Dict[str, Any], 
                                   chat_sample: str = "") -> Dict[str, Any]:
        """
        T051: ç”Ÿæˆä¸ªäººæ€»ç»“ - åˆ›æ„é£æ ¼çš„å¹´åº¦æŠ¥å‘Š
        
        Args:
            stats: PersonalStats.to_dict() çš„ç»“æœ
            chat_sample: å¯é€‰çš„èŠå¤©è®°å½•æ ·æœ¬
        
        Returns:
            {'success': bool, 'summary': str, 'error': str}
        """
        if not self.is_available():
            return {
                'success': False,
                'summary': '',
                'error': 'AIæœåŠ¡æœªé…ç½®ï¼Œè¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡'
            }
        
        prompt = self._build_personal_prompt(stats, chat_sample)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self._get_system_prompt('personal')},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=self.max_tokens,
                temperature=0.8  # å¢åŠ åˆ›æ„æ€§
            )
            
            summary = response.choices[0].message.content
            
            return {
                'success': True,
                'summary': summary,
                'tokens_used': response.usage.total_tokens if response.usage else 0,
                'model': self.model
            }
        except Exception as e:
            logger.error(f"Personal summary generation failed: {e}")
            return {
                'success': False,
                'summary': '',
                'error': str(e)
            }
    
    def generate_group_summary(self, stats: Dict[str, Any],
                                chat_sample: str = "") -> Dict[str, Any]:
        """
        ç”Ÿæˆç¾¤ä½“æ€»ç»“
        
        Args:
            stats: GroupStats.to_dict() çš„ç»“æœ
            chat_sample: å¯é€‰çš„èŠå¤©è®°å½•æ ·æœ¬
        
        Returns:
            {'success': bool, 'summary': str, 'error': str}
        """
        if not self.is_available():
            return {
                'success': False,
                'summary': '',
                'error': 'AIæœåŠ¡æœªé…ç½®ï¼Œè¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡'
            }
        
        prompt = self._build_group_prompt(stats, chat_sample)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self._get_system_prompt('group')},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=self.max_tokens,
                temperature=0.8
            )
            
            summary = response.choices[0].message.content
            
            return {
                'success': True,
                'summary': summary,
                'tokens_used': response.usage.total_tokens if response.usage else 0,
                'model': self.model
            }
        except Exception as e:
            logger.error(f"Group summary generation failed: {e}")
            return {
                'success': False,
                'summary': '',
                'error': str(e)
            }
    
    def generate_network_summary(self, stats: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç”Ÿæˆç¤¾äº¤ç½‘ç»œæ€»ç»“
        
        Args:
            stats: NetworkStats.to_dict() çš„ç»“æœ
        
        Returns:
            {'success': bool, 'summary': str, 'error': str}
        """
        if not self.is_available():
            return {
                'success': False,
                'summary': '',
                'error': 'AIæœåŠ¡æœªé…ç½®ï¼Œè¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡'
            }
        
        prompt = self._build_network_prompt(stats)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self._get_system_prompt('network')},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=self.max_tokens,
                temperature=0.8
            )
            
            summary = response.choices[0].message.content
            
            return {
                'success': True,
                'summary': summary,
                'tokens_used': response.usage.total_tokens if response.usage else 0,
                'model': self.model
            }
        except Exception as e:
            logger.error(f"Network summary generation failed: {e}")
            return {
                'success': False,
                'summary': '',
                'error': str(e)
            }
    
    def _get_system_prompt(self, summary_type: str) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        
        base_style = """
ä½ æ˜¯ä¸€ä¸ªè¶…çº§æœ‰è¶£çš„èŠå¤©è®°å½•åˆ†æå¸ˆï¼Œé£æ ¼åŒ…å«ï¼š
- ğŸ® è¾£è¯„ï¼šæ¯’èˆŒä½†ä¸ä¼¤äººï¼Œåæ§½ä¸­å¸¦ç€çˆ±
- ğŸµ æ¸©æƒ…è„‰è„‰ï¼šå……æ»¡ä»ªå¼æ„Ÿå’Œäººæƒ…å‘³
- ğŸ“± æ•°æ®å¯è§†åŒ–é£æ ¼ï¼šç”¨æ•°æ®è®²æ•…äº‹

å†™ä½œè¦æ±‚ï¼š
1. ä½¿ç”¨æœ‰è¶£çš„è¯­è¨€ï¼Œè®©æŠ¥å‘Šç”ŸåŠ¨æœ‰è¶£
2. åˆ›é€ é’ˆå¯¹å•ä¸ªç”¨æˆ·ï¼ˆæ˜µç§°ç§°å‘¼ï¼Œä½†ç”¨QQå·åŒºåˆ†ï¼‰ä¸ªæ€§åŒ–çš„"ç§°å·"å’Œ"æˆå°±å¾½ç« "
3. ç”¨ç½‘ç»œçƒ­æ¢—å’Œæµè¡Œè¯­ï¼Œä½†ä¸è¦å¤ªè¿‡æ—¶
4. æ•°æ®è¦å…·ä½“ï¼Œä½†è¡¨è¾¾è¦æœ‰è¶£
5. é€‚åº¦æ¯’èˆŒåæ§½ï¼Œä½†è¦è®©äººä¼šå¿ƒä¸€ç¬‘è€Œä¸æ˜¯ç”Ÿæ°”
6. æœ€åç»™ä¸€ä¸ªæ€»ç»“

è¾“å‡ºæ ¼å¼ï¼šä½¿ç”¨Markdownæ ¼å¼ï¼ŒåŒ…å«æ ‡é¢˜ã€åŠ ç²—ç­‰
"""
        
        type_specific = {
            'personal': """
## ä¸ªäººæŠ¥å‘Šç‰¹æ®Šè¦æ±‚ï¼š

æ ¹æ®ç”¨æˆ·çš„èŠå¤©æ•°æ®ï¼Œç”Ÿæˆä¸€ä»½ä¸ªæ€§åŒ–çš„"å¹´åº¦äººè®¾æŠ¥å‘Š"ï¼ŒåŒ…å«ï¼š

1. **å¼€åœºç™½** - ç”¨ä¸€å¥è¯æ¦‚æ‹¬è¿™ä¸ªäººçš„ç¾¤èŠäººè®¾
2. **ä¸“å±ç§°å·** - æ ¹æ®æ•°æ®ç»™å‡º2-3ä¸ªæœ‰è¶£çš„ç§°å·ï¼Œä¾‹å¦‚ï¼š
   - ğŸŒ™ "å‡Œæ™¨ä¸‰ç‚¹ã®ç¾¤èŠå®ˆæŠ¤è€…" (å¦‚æœæ·±å¤œæ´»è·ƒ)
   - ğŸ” "æ—©èµ·æ‰“å¡ç¬¬ä¸€äºº" (å¦‚æœæ—©èµ·æ´»è·ƒ)  
   - ğŸ’¬ "æ—¥å‡999+æ¶ˆæ¯ã®è¯ç—¨" (å¦‚æœæ¶ˆæ¯å¤š)
   - ğŸ¤« "ç¥ç§˜æ½œæ°´å‘˜" (å¦‚æœæ¶ˆæ¯å°‘)
   - ğŸ“¸ "è¡¨æƒ…åŒ…ã®ä¼ æ•™å£«" (å¦‚æœè¡¨æƒ…å¤š)

3. **æ•°æ®äº®ç‚¹** - æŒ‘é€‰æœ€æœ‰è¶£çš„2-3ä¸ªæ•°æ®ç‚¹ï¼Œç”¨æœ‰è¶£çš„æ–¹å¼å‘ˆç°
4. **ç¾¤èŠç”»é£åˆ†æ** - æ ¹æ®çƒ­è¯å’Œæ¶ˆæ¯ç‰¹ç‚¹åˆ†ætaçš„è¯´è¯é£æ ¼
5. **å¹´åº¦é‡‘å¥** - å¦‚æœæœ‰èŠå¤©æ ·æœ¬ï¼ŒæŒ‘ä¸€å¥æœ€æœ‰ä»£è¡¨æ€§çš„
6. **æ¯’èˆŒåæ§½** - ä¸€å°æ®µå‹å–„çš„åæ§½
""",
            'group': """
## ç¾¤ä½“æŠ¥å‘Šç‰¹æ®Šè¦æ±‚ï¼š

ç”Ÿæˆä¸€ä»½ç¾¤èŠçš„"å¹´åº¦ç¾¤åƒæŠ¥å‘Š"ï¼Œåƒæ˜¯ç»™è¿™ä¸ªç¾¤é¢å‘çš„å¹´åº¦å¤§å¥–ï¼ŒåŒ…å«ï¼š

1. **ç¾¤èŠæ¡£æ¡ˆ** - ä¸€å¥è¯æ¦‚æ‹¬è¿™ä¸ªç¾¤çš„æ°”è´¨
2. **ç¾¤æ´»åŠ›æŒ‡æ•°** - æ ¹æ®æ¶ˆæ¯é‡è¯„çº§ï¼Œç»™ä¸ªæœ‰è¶£çš„è¯„è¯­å¦‚ï¼š
   - ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ "æ¯”æ˜¥æ™šå¼¹å¹•è¿˜çƒ­é—¹"
   - ğŸ”¥ğŸ”¥ğŸ”¥ "ä¸‰å¤©ä¸çœ‹å°±999+"
   - ğŸ”¥ "å®‰é™å¾—åƒä¸ªå­¦ä¹ ç¾¤"

3. **å¹´åº¦MVPæ¦œå•** - ç»™æ ¸å¿ƒæˆå‘˜é¢å¥–ï¼š
   - ğŸ‘‘ è¯ç—¨ä¹‹ç‹
   - ğŸŒ™ æ·±å¤œå®ˆæŠ¤è€…
   - ğŸŒ… æ—©èµ·å·ç‹
   - ğŸ“¸ è¡¨æƒ…åŒ…å¤§æˆ·
   
4. **ç¾¤èŠçƒ­è¯äº‘** - åˆ†æçƒ­è¯ï¼Œåæ§½ç¾¤èŠç”»é£
5. **æ´»è·ƒæ—¶é—´æ®µåˆ†æ** - è¿™ä¸ªç¾¤ä»€ä¹ˆæ—¶å€™æœ€æ´»è·ƒï¼Œç»™ä¸ªæœ‰è¶£çš„è§£è¯»
6. **å¹´åº¦å¤§äº‹è®°** - æ ¹æ®æœˆåº¦è¶‹åŠ¿çŒœæµ‹ç¾¤é‡Œå‘ç”Ÿè¿‡ä»€ä¹ˆ
7. **ç¾¤èŠç”»é£é‰´å®š** - è¿™æ˜¯ä¸ªä»€ä¹ˆç±»å‹çš„ç¾¤
""",
            'network': """
## ç¤¾äº¤ç½‘ç»œæŠ¥å‘Šç‰¹æ®Šè¦æ±‚ï¼š

ç”Ÿæˆä¸€ä»½"ç¾¤èŠç¤¾äº¤å›¾è°±æŠ¥å‘Š"ï¼Œæ­ç§˜ç¾¤é‡Œçš„äººé™…å…³ç³»ï¼ŒåŒ…å«ï¼š

1. **ç¤¾äº¤å›¾è°±æ€»è§ˆ** - ä¸€å¥è¯æ¦‚æ‹¬è¿™ä¸ªç¾¤çš„ç¤¾äº¤ç‰¹ç‚¹
2. **ç¤¾äº¤ä¸­å¿ƒ** - è°æ˜¯ç¾¤é‡Œçš„ç¤¾äº¤è¾¾äººï¼Œç»™taä¸€ä¸ªç§°å·
3. **æœ€ä½³CP** - äº’åŠ¨æœ€å¤šçš„ç»„åˆï¼Œç»™ä»–ä»¬ä¸€ä¸ªCPå
4. **å°åœˆå­åˆ†æ** - ç¾¤é‡Œæœ‰å“ªäº›å°å›¢ä½“
5. **ç¤¾äº¤å†·çŸ¥è¯†** - ä¸€äº›æœ‰è¶£çš„äº’åŠ¨æ•°æ®
6. **äººé™…å…³ç³»å›¾é‰´** - æ ¹æ®ç½‘ç»œç‰¹å¾åˆ†æç¾¤çš„ç¤¾äº¤æ°›å›´
7. **ç¤¾äº¤è¾¾äººå»ºè®®** - ç»™æ½œæ°´å…šçš„ç¤¾äº¤å»ºè®®ï¼ˆè°ƒä¾ƒå‘ï¼‰
"""
        }
        
        return base_style + type_specific.get(summary_type, '')
    
    def _build_personal_prompt(self, stats: Dict[str, Any], 
                                chat_sample: str = "") -> str:
        """æ„å»ºä¸ªäººæ€»ç»“çš„ç”¨æˆ·æç¤ºè¯"""
        
        # æå–å…³é”®æ•°æ®
        nickname = stats.get('nickname', 'ç¥ç§˜ç”¨æˆ·')
        qq = stats.get('qq', 'unknown')
        total_messages = stats.get('total_messages', 0)
        active_days = stats.get('active_days', 0)
        time_dist = stats.get('time_distribution', {})
        user_type = stats.get('user_type', 'æ™®é€šç”¨æˆ·')
        at_count = stats.get('at_count', 0)
        being_at_count = stats.get('being_at_count', 0)
        avg_length = stats.get('avg_message_length', 0)
        image_count = stats.get('image_count', 0)
        emoji_count = stats.get('emoji_count', 0)
        top_words = stats.get('top_words', [])
        max_streak = stats.get('max_streak_days', 0)
        monthly = stats.get('monthly_messages', {})
        
        # æ‰¾å‡ºæœ€æ´»è·ƒçš„æ—¶æ®µ
        peak_time = max(time_dist.items(), key=lambda x: x[1])[0] if time_dist else 'æœªçŸ¥'
        
        # æ‰¾å‡ºæœ€æ´»è·ƒçš„æœˆä»½
        peak_month = max(monthly.items(), key=lambda x: x[1])[0] if monthly else 'æœªçŸ¥'
        
        # çƒ­è¯å­—ç¬¦ä¸²
        hot_words_str = ', '.join([w['word'] for w in top_words[:10]]) if top_words else 'æ— '
        
        prompt = f"""
è¯·ä¸ºä»¥ä¸‹ç”¨æˆ·ç”Ÿæˆä¸€ä»½æœ‰è¶£çš„ä¸ªäººèŠå¤©æŠ¥å‘Šï¼š

## ğŸ“Š ç”¨æˆ·æ•°æ®

- **æ˜µç§°**: {nickname}
- **QQå·**: {qq}
- **æ€»æ¶ˆæ¯æ•°**: {total_messages} æ¡
- **æ´»è·ƒå¤©æ•°**: {active_days} å¤©
- **æœ€é•¿è¿ç»­æ´»è·ƒ**: {max_streak} å¤©
- **ç”¨æˆ·ç±»å‹**: {user_type}
- **æœ€æ´»è·ƒæ—¶æ®µ**: {peak_time}
- **æœ€æ´»è·ƒæœˆä»½**: {peak_month}

## ğŸ“ˆ äº’åŠ¨æ•°æ®
- **@åˆ«äººæ¬¡æ•°**: {at_count} æ¬¡
- **è¢«@æ¬¡æ•°**: {being_at_count} æ¬¡
- **å¹³å‡æ¶ˆæ¯é•¿åº¦**: {avg_length:.1f} å­—
- **å‘é€å›¾ç‰‡**: {image_count} å¼ 
- **å‘é€è¡¨æƒ…**: {emoji_count} ä¸ª

## ğŸ”¥ çƒ­è¯TOP10
{hot_words_str}

## â° æ—¶æ®µåˆ†å¸ƒ
{json.dumps(time_dist, ensure_ascii=False, indent=2)}

## ğŸ“… æœˆåº¦æ¶ˆæ¯é‡
{json.dumps(monthly, ensure_ascii=False, indent=2)}
"""
        
        if chat_sample:
            prompt += f"""
## ğŸ’¬ èŠå¤©æ ·æœ¬ï¼ˆç”¨äºåˆ†æè¯´è¯é£æ ¼ï¼‰
{chat_sample[:2000]}
"""
        
        prompt += """
è¯·æ ¹æ®ä»¥ä¸Šæ•°æ®ï¼Œç”Ÿæˆä¸€ä»½æœ‰è¶£åˆ›æ„çš„ä¸ªäººå¹´åº¦æ€»ç»“ï¼
"""
        
        return prompt
    
    def _build_group_prompt(self, stats: Dict[str, Any],
                             chat_sample: str = "") -> str:
        """æ„å»ºç¾¤ä½“æ€»ç»“çš„ç”¨æˆ·æç¤ºè¯"""
        
        total_messages = stats.get('total_messages', 0)
        daily_avg = stats.get('daily_average', 0)
        peak_hours = stats.get('peak_hours', [])
        core_members = stats.get('core_members', [])
        active_members = stats.get('active_members', [])
        normal_members = stats.get('normal_members', [])
        lurkers = stats.get('lurkers', [])
        hot_words = stats.get('hot_words', [])
        monthly_trend = stats.get('monthly_trend', {})
        text_ratio = stats.get('text_ratio', 0)
        image_ratio = stats.get('image_ratio', 0)
        emoji_ratio = stats.get('emoji_ratio', 0)
        
        # æ ¸å¿ƒæˆå‘˜ä¿¡æ¯
        core_info = []
        for m in core_members[:5]:
            if isinstance(m, dict):
                core_info.append(f"{m.get('name', m.get('qq', '?'))} ({m.get('count', 0)}æ¡)")
            else:
                core_info.append(str(m))
        
        # çƒ­è¯
        hot_words_str = ', '.join([w['word'] for w in hot_words[:15]]) if hot_words else 'æ— '
        
        # å³°å€¼æ—¶é—´
        peak_str = ', '.join([f"{h}:00" for h in peak_hours[:3]]) if peak_hours else 'æœªçŸ¥'
        
        prompt = f"""
è¯·ä¸ºä»¥ä¸‹ç¾¤èŠç”Ÿæˆä¸€ä»½æœ‰è¶£çš„ç¾¤ä½“å¹´åº¦æŠ¥å‘Šï¼š

## ğŸ“Š ç¾¤èŠæ•°æ®

- **æ€»æ¶ˆæ¯æ•°**: {total_messages} æ¡
- **æ—¥å‡æ¶ˆæ¯**: {daily_avg:.1f} æ¡
- **æœ€æ´»è·ƒæ—¶æ®µ**: {peak_str}

## ğŸ‘¥ æˆå‘˜æ„æˆ
- **æ ¸å¿ƒæˆå‘˜** (TOP 10%): {len(core_members)} äºº
- **æ´»è·ƒæˆå‘˜** (10%-40%): {len(active_members)} äºº
- **æ™®é€šæˆå‘˜** (40%-80%): {len(normal_members)} äºº
- **æ½œæ°´å‘˜** (Bottom 20%): {len(lurkers)} äºº

## ğŸ‘‘ è¯ç—¨æ’è¡Œæ¦œTOP5
{chr(10).join(core_info) if core_info else 'æš‚æ— æ•°æ®'}

## ğŸ’¬ æ¶ˆæ¯ç±»å‹å æ¯”
- æ–‡å­—æ¶ˆæ¯: {text_ratio*100:.1f}%
- å›¾ç‰‡æ¶ˆæ¯: {image_ratio*100:.1f}%
- è¡¨æƒ…æ¶ˆæ¯: {emoji_ratio*100:.1f}%

## ğŸ”¥ ç¾¤èŠçƒ­è¯TOP15
{hot_words_str}

## ğŸ“… æœˆåº¦è¶‹åŠ¿
{json.dumps(monthly_trend, ensure_ascii=False, indent=2)}
"""
        
        if chat_sample:
            prompt += f"""
## ğŸ’¬ èŠå¤©æ ·æœ¬ï¼ˆç”¨äºåˆ†æç¾¤èŠç”»é£ï¼‰
{chat_sample[:2000]}
"""
        
        prompt += """
è¯·æ ¹æ®ä»¥ä¸Šæ•°æ®ï¼Œç”Ÿæˆä¸€ä»½æœ‰è¶£åˆ›æ„çš„ç¾¤èŠå¹´åº¦æ€»ç»“ï¼
"""
        
        return prompt
    
    def _build_network_prompt(self, stats: Dict[str, Any]) -> str:
        """æ„å»ºç¤¾äº¤ç½‘ç»œæ€»ç»“çš„ç”¨æˆ·æç¤ºè¯"""
        
        total_nodes = stats.get('total_nodes', 0)
        total_edges = stats.get('total_edges', 0)
        density = stats.get('density', 0)
        avg_clustering = stats.get('avg_clustering_coefficient', 0)
        communities = stats.get('communities', [])
        most_popular = stats.get('most_popular_user', {})
        most_active_pair = stats.get('most_active_pair', {})
        key_connectors = stats.get('key_connectors', [])
        
        # ç¤¾äº¤ä¸­å¿ƒ
        popular_info = "æ— "
        if most_popular:
            popular_info = f"{most_popular.get('name', most_popular.get('qq', '?'))} (ä¸­å¿ƒåº¦: {most_popular.get('centrality', 0)*100:.1f}%)"
        
        # æœ€ä½³CP
        pair_info = "æ— "
        if most_active_pair:
            pair = most_active_pair.get('pair', [])
            if len(pair) >= 2:
                pair_info = f"{pair[0]} â†” {pair[1]} (äº’åŠ¨{most_active_pair.get('weight', 0):.0f}æ¬¡)"
        
        # å…³é”®è¿æ¥è€…
        connectors_info = []
        for c in key_connectors[:3]:
            if isinstance(c, dict):
                connectors_info.append(f"{c.get('name', c.get('qq', '?'))}")
        
        # ç¤¾åŒºä¿¡æ¯
        community_info = f"{len(communities)} ä¸ªå°åœˆå­" if communities else "æš‚æ— æ˜æ˜¾å°åœˆå­"
        
        prompt = f"""
è¯·ä¸ºä»¥ä¸‹ç¾¤èŠç¤¾äº¤ç½‘ç»œç”Ÿæˆä¸€ä»½æœ‰è¶£çš„ç¤¾äº¤å›¾è°±æŠ¥å‘Šï¼š

## ğŸ•¸ï¸ ç½‘ç»œæ¦‚å†µ

- **å‚ä¸äº’åŠ¨çš„æˆå‘˜**: {total_nodes} äºº
- **äº’åŠ¨å…³ç³»æ•°**: {total_edges} æ¡
- **ç½‘ç»œå¯†åº¦**: {density*100:.1f}%
- **å¹³å‡èšç±»ç³»æ•°**: {avg_clustering:.3f}

## ğŸ‘‘ ç¤¾äº¤ä¸­å¿ƒï¼ˆäººæ°”ç‹ï¼‰
{popular_info}

## ğŸ’• æœ€ä½³CPï¼ˆäº’åŠ¨æœ€å¤šçš„ç»„åˆï¼‰
{pair_info}

## ğŸŒ‰ å…³é”®è¿æ¥è€…ï¼ˆç¤¾äº¤æ¡¥æ¢ï¼‰
{', '.join(connectors_info) if connectors_info else 'æš‚æ— æ˜æ˜¾æ¡¥æ¢äººç‰©'}

## ğŸ‘¥ å°åœˆå­åˆ†æ
{community_info}

è¯·æ ¹æ®ä»¥ä¸Šæ•°æ®ï¼Œç”Ÿæˆä¸€ä»½å¹´åº¦æŠ¥å‘Šé£æ ¼çš„ç¤¾äº¤ç½‘ç»œåˆ†æï¼
æ­ç§˜ç¾¤é‡Œçš„äººé™…å…³ç³»ï¼Œç»™CPèµ·åï¼Œåˆ†æå°åœˆå­ï¼Œæœ€åç»™ç¤¾æ/æ½œæ°´å…šä¸€äº›è°ƒä¾ƒå»ºè®®ã€‚
"""
        
        return prompt


# å¿«æ·å‡½æ•°
def generate_summary(summary_type: str, stats: Dict[str, Any], 
                     chat_sample: str = "") -> Dict[str, Any]:
    """
    å¿«é€Ÿç”ŸæˆAIæ€»ç»“
    
    Args:
        summary_type: 'personal', 'group', æˆ– 'network'
        stats: å¯¹åº”çš„ç»Ÿè®¡æ•°æ®
        chat_sample: å¯é€‰çš„èŠå¤©æ ·æœ¬
    
    Returns:
        {'success': bool, 'summary': str, 'error': str}
    """
    summarizer = AISummarizer()
    
    if summary_type == 'personal':
        return summarizer.generate_personal_summary(stats, chat_sample)
    elif summary_type == 'group':
        return summarizer.generate_group_summary(stats, chat_sample)
    elif summary_type == 'network':
        return summarizer.generate_network_summary(stats)
    else:
        return {
            'success': False,
            'summary': '',
            'error': f'Unknown summary type: {summary_type}'
        }
